{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"bash-notes/","text":"Bash shell tips and trics Hiding top panel in elementaryOS To hide the top panel in elementaryOS the shell script below have to be saved to a text file and named withouth any file extension: #!/bin/bash result=`ps aux | grep -i \"io.elementary.wingpanel\" | grep -v \"grep\" | wc -l` if [ $result -ge 1 ] then killall io.elementary.wingpanel &> /dev/null; killall io.elementary.wingpanel &> /dev/null; killall io.elementary.wingpanel &> /dev/null; else io.elementary.wingpanel &> /dev/null & fi Change the file permission so it can be executed by the user: chmod 755 hide_top_panel Save the file to /bin . Add a custom shortcut to elementaryOS. Go to System Settings -> Hardware -> Keyboard -> Shortcuts tab -> Custom. Select a keyboard shortcut of you preference and use the same name as the file name in /bin .","title":"Bash"},{"location":"bash-notes/#bash-shell-tips-and-trics","text":"","title":"Bash shell tips and trics"},{"location":"bash-notes/#hiding-top-panel-in-elementaryos","text":"To hide the top panel in elementaryOS the shell script below have to be saved to a text file and named withouth any file extension: #!/bin/bash result=`ps aux | grep -i \"io.elementary.wingpanel\" | grep -v \"grep\" | wc -l` if [ $result -ge 1 ] then killall io.elementary.wingpanel &> /dev/null; killall io.elementary.wingpanel &> /dev/null; killall io.elementary.wingpanel &> /dev/null; else io.elementary.wingpanel &> /dev/null & fi Change the file permission so it can be executed by the user: chmod 755 hide_top_panel Save the file to /bin . Add a custom shortcut to elementaryOS. Go to System Settings -> Hardware -> Keyboard -> Shortcuts tab -> Custom. Select a keyboard shortcut of you preference and use the same name as the file name in /bin .","title":"Hiding top panel in elementaryOS"},{"location":"conda-notes/","text":"How to work with conda Conda is an open source package management system and environment management system that runs on Windows, macOS, and Linux. Conda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Its documentation cand be found in https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/ Basics about the tool can be accessed with the help command ~$ conda --help Installed version cand be checked with: ~$ conda --version ~$ conda -v Detailed information shall be checked with: ~$ conda list A quick health check of your environment can be run with: ~$ conda doctor --name base To update conda itself you can use the update argument: ~$ conda update conda If you want to update all installed packages do: ~$ conda update --all Or specify the environment to update all packages in it: ~$ conda update -n hero --all Dealing with conda environments Conda environments can be created with: ~$ conda create --name myenv ~$ conda create -n myenv python=3.6 ~$ conda create -n myenv scipy ~$ conda create -n myenv scipy=0.15.0 There is also the option to export an environment config to an yml file and use it in another computer to create a new environment with the same config: ~$ conda env export > environment.yml ~$ conda env create -f environment.yml Listing, activating and deactivation environments is quite simple: ~$ conda env list ~$ conda activate myenv ~$ conda deactivate myenv To check the location of your environments and remove a specific environment use the two following commands: ~$ conda info --envs ~$ conda remove --name myenv --all Installing packages with conda ~$ conda search pandas ~$ conda install scipy ~$ conda install --name myenv scipy ~$ conda install scipy=0.15.0","title":"Conda"},{"location":"conda-notes/#how-to-work-with-conda","text":"Conda is an open source package management system and environment management system that runs on Windows, macOS, and Linux. Conda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language. Its documentation cand be found in https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/ Basics about the tool can be accessed with the help command ~$ conda --help Installed version cand be checked with: ~$ conda --version ~$ conda -v Detailed information shall be checked with: ~$ conda list A quick health check of your environment can be run with: ~$ conda doctor --name base To update conda itself you can use the update argument: ~$ conda update conda If you want to update all installed packages do: ~$ conda update --all Or specify the environment to update all packages in it: ~$ conda update -n hero --all","title":"How to work with conda"},{"location":"conda-notes/#dealing-with-conda-environments","text":"Conda environments can be created with: ~$ conda create --name myenv ~$ conda create -n myenv python=3.6 ~$ conda create -n myenv scipy ~$ conda create -n myenv scipy=0.15.0 There is also the option to export an environment config to an yml file and use it in another computer to create a new environment with the same config: ~$ conda env export > environment.yml ~$ conda env create -f environment.yml Listing, activating and deactivation environments is quite simple: ~$ conda env list ~$ conda activate myenv ~$ conda deactivate myenv To check the location of your environments and remove a specific environment use the two following commands: ~$ conda info --envs ~$ conda remove --name myenv --all","title":"Dealing with conda environments"},{"location":"conda-notes/#installing-packages-with-conda","text":"~$ conda search pandas ~$ conda install scipy ~$ conda install --name myenv scipy ~$ conda install scipy=0.15.0","title":"Installing packages with conda"},{"location":"git-notes/","text":"Git Check if git is atually installed in your system. ~$ git --version Setting up local and remote repositories Create a new repo on github.com. Do not add a README or License just yet. Open a terminal at your local project directory and run: $ git init -b main The local direcotry in now a Git repo. You can add some initial files to your local repo, like the example below: $ echo \"# project_palmer-penguins\" >> README.md A good practice is to create a .gitigonre file and have it as a space to add itens you don~t want to track with git. $ touch .gitignore Next step is to add the files to the stage area of your local repo and then commit the changes. Remember that a commit is a check-point in time of the changes made. $ git add README.md $ git commit -m \"initial commit\" Linking your local repo with you github account is straight forward $ git remote add origin <REMOTE_URL> $ git push -u origin main Usefull commands to know Checking your local repo status $ git status Adding files to the stage area of your local repo can ve done in different ways. $ git add <file1> <file2> $ git add . To unstage the file or files: $ git rm --cached <file1> # to unstaged the file If you want to have a look at the log of commits in your repo you can use the following methods: $ git log $ git log --oneline Configuring global settings Check current configuration with: $ git config user.name $ git config user.email To set email and user name: $ git config --global user.name \"User Name\" $ git config --global user.email \"email@email.com\" Git branches navigate to your local repo make sure local repo and remote repo are up to date run the following command to start a new branch: T0 create a local new branch and to push it to your GitHub repository run: $ git checkout -b <your-new-branch-name> $ git push origin <your-new-branch-name> Once your work is done you can merge your branch back into the main branch. Use git merge to merge the specified branch into the currently active branch. Just maae sure you are on the branch that we are merging into. See steps below $ git checkout main Pull the remote main changes to the local main branch $ git pull origin main Merge your branch to the currently active branch git merge <your-new-branch-name> To verify branch history $ git log --all --decorate --oneline --graph","title":"Git"},{"location":"git-notes/#git","text":"Check if git is atually installed in your system. ~$ git --version","title":"Git"},{"location":"git-notes/#setting-up-local-and-remote-repositories","text":"Create a new repo on github.com. Do not add a README or License just yet. Open a terminal at your local project directory and run: $ git init -b main The local direcotry in now a Git repo. You can add some initial files to your local repo, like the example below: $ echo \"# project_palmer-penguins\" >> README.md A good practice is to create a .gitigonre file and have it as a space to add itens you don~t want to track with git. $ touch .gitignore Next step is to add the files to the stage area of your local repo and then commit the changes. Remember that a commit is a check-point in time of the changes made. $ git add README.md $ git commit -m \"initial commit\" Linking your local repo with you github account is straight forward $ git remote add origin <REMOTE_URL> $ git push -u origin main","title":"Setting up local and remote repositories"},{"location":"git-notes/#usefull-commands-to-know","text":"Checking your local repo status $ git status Adding files to the stage area of your local repo can ve done in different ways. $ git add <file1> <file2> $ git add . To unstage the file or files: $ git rm --cached <file1> # to unstaged the file If you want to have a look at the log of commits in your repo you can use the following methods: $ git log $ git log --oneline","title":"Usefull commands to know"},{"location":"git-notes/#configuring-global-settings","text":"Check current configuration with: $ git config user.name $ git config user.email To set email and user name: $ git config --global user.name \"User Name\" $ git config --global user.email \"email@email.com\"","title":"Configuring global settings"},{"location":"git-notes/#git-branches","text":"navigate to your local repo make sure local repo and remote repo are up to date run the following command to start a new branch: T0 create a local new branch and to push it to your GitHub repository run: $ git checkout -b <your-new-branch-name> $ git push origin <your-new-branch-name> Once your work is done you can merge your branch back into the main branch. Use git merge to merge the specified branch into the currently active branch. Just maae sure you are on the branch that we are merging into. See steps below $ git checkout main Pull the remote main changes to the local main branch $ git pull origin main Merge your branch to the currently active branch git merge <your-new-branch-name> To verify branch history $ git log --all --decorate --oneline --graph","title":"Git branches"},{"location":"home/","text":"Welcome to My Notes This is an open space where I drop notes on technical subjects that at one point in time were usefull to me. I do not own the information in this page and it is saved here for my own future reference. Feel free to contact me here if you have any questions, suggestions or complains.","title":"Home"},{"location":"home/#welcome-to-my-notes","text":"This is an open space where I drop notes on technical subjects that at one point in time were usefull to me. I do not own the information in this page and it is saved here for my own future reference. Feel free to contact me here if you have any questions, suggestions or complains.","title":"Welcome to My Notes"},{"location":"linux-notes/","text":"Linux tips and trics A small collection of notes about usefull linux commands. Archiving in linux tar - is an archiving program designed to store and extract files from an archive file known as tarfile to create it, move files you intend to bzip2 into a directory, for instance /home/user/test , and run the following command: tar -cjf tarfilename.tar.bz2 teste/ It will create (c), bzip2 (j), the files (f) in that directory teste/ into the tarfile tarfilename.tar.bz2 to extract a tarfile into a directory, simple run the following command tar \u2013xjf tarfilename.tar.bz2 teste/ It will extract (x) bzipped (j) files (f) in the tarfile back to the directory teste/ Source lists A repository is basically a web server that has packages (software). The package manager gets these packages from the repositories. How does the apt package manager know the address of the repositories? The answer is sources.list file. What does sources.list do? It\u2019s basically a text file that contains the repository details. Each uncommented line represents a separate repository. The lines follow a specific format, though. It\u2019s usually composed of this: archive-type repository-url distribution component I know that\u2019s not easy to understand. Let\u2019s take a look at one of the actual lines: deb http://archive.ubuntu.com/ubuntu impish main restricted Archive type is deb here, meaning you\u2019ll get precompiled .deb packages. Another archive type is deb-src which provides the actual source code but usually it is commented out (not used by the system) because a regular user doesn\u2019t need the source code of an application. The deb file lets you install the package. Repository URL is http://archive.ubuntu.com/ubuntu. In fact, you can visit this URL and see various available folders (that contain the package details). Next, the distribution is impish. On the actual repository, it is represented as dists. It\u2019s because there are several categories of repositories like impish-security (for security packages), impish-backports (for backported packages) etc. This is why it\u2019s not just the distribution name. So, you can go to this URL http://archive.ubuntu.com/ubuntu/dists/ and see that impish (codename for Ubuntu 21.10) is one of the available folders among many other choices here. The component is one of the five types of default Ubuntu repositories. You can combine more than one (if available) in the same line, actually. Instead of writing two lines like this: deb http://archive.ubuntu.com/ubuntu impish main deb http://archive.ubuntu.com/ubuntu impish restricted You write two of them together like this: deb http://archive.ubuntu.com/ubuntu impish main restricted This means when you have a repository detail like \"deb http://archive.ubuntu.com/ubuntu impish main\" in the sources.list, it gets software packages details stored at http://archive.ubuntu.com/ubuntu/dists/impish/main/ The distribution code name is important. Now imagine if someone is using an old, unsupported version of Ubuntu like Ubuntu 20.10 codenamed Groovy Gorilla. The sources.list file will contain repository URL like \"deb http://archive.ubuntu.com/ubuntu groovy main\". And then it becomes problematic because if you visit http://archive.ubuntu.com/ubuntu/dists URL, you won\u2019t find groovy folder here. Since Ubuntu 20.10 is no longer maintained, its folder has been removed. As a result, Ubuntu will show an error like \u2018release file not found\u2019 or \u2018error 404 repository not found\u2019. sources.list file and sources.list.d directory If you look at the /etc/apt directory, you\u2019ll notice a directory called sources.list.d. The idea is that the primary sources.list file is for the official Ubuntu repositories and for any external repositories and PPA, you add a .list file (with the repository details) in this sources.list.d directory. This makes managing the repositories easier as you don\u2019t mess up with the default repositories. The external repositories can be easily disabled (by adding # in front of the repository details) or removed (by removing its corresponding .list file).","title":"Linux"},{"location":"linux-notes/#linux-tips-and-trics","text":"A small collection of notes about usefull linux commands.","title":"Linux tips and trics"},{"location":"linux-notes/#archiving-in-linux","text":"tar - is an archiving program designed to store and extract files from an archive file known as tarfile to create it, move files you intend to bzip2 into a directory, for instance /home/user/test , and run the following command: tar -cjf tarfilename.tar.bz2 teste/ It will create (c), bzip2 (j), the files (f) in that directory teste/ into the tarfile tarfilename.tar.bz2 to extract a tarfile into a directory, simple run the following command tar \u2013xjf tarfilename.tar.bz2 teste/ It will extract (x) bzipped (j) files (f) in the tarfile back to the directory teste/","title":"Archiving in linux"},{"location":"linux-notes/#source-lists","text":"A repository is basically a web server that has packages (software). The package manager gets these packages from the repositories. How does the apt package manager know the address of the repositories? The answer is sources.list file. What does sources.list do? It\u2019s basically a text file that contains the repository details. Each uncommented line represents a separate repository. The lines follow a specific format, though. It\u2019s usually composed of this: archive-type repository-url distribution component I know that\u2019s not easy to understand. Let\u2019s take a look at one of the actual lines: deb http://archive.ubuntu.com/ubuntu impish main restricted Archive type is deb here, meaning you\u2019ll get precompiled .deb packages. Another archive type is deb-src which provides the actual source code but usually it is commented out (not used by the system) because a regular user doesn\u2019t need the source code of an application. The deb file lets you install the package. Repository URL is http://archive.ubuntu.com/ubuntu. In fact, you can visit this URL and see various available folders (that contain the package details). Next, the distribution is impish. On the actual repository, it is represented as dists. It\u2019s because there are several categories of repositories like impish-security (for security packages), impish-backports (for backported packages) etc. This is why it\u2019s not just the distribution name. So, you can go to this URL http://archive.ubuntu.com/ubuntu/dists/ and see that impish (codename for Ubuntu 21.10) is one of the available folders among many other choices here. The component is one of the five types of default Ubuntu repositories. You can combine more than one (if available) in the same line, actually. Instead of writing two lines like this: deb http://archive.ubuntu.com/ubuntu impish main deb http://archive.ubuntu.com/ubuntu impish restricted You write two of them together like this: deb http://archive.ubuntu.com/ubuntu impish main restricted This means when you have a repository detail like \"deb http://archive.ubuntu.com/ubuntu impish main\" in the sources.list, it gets software packages details stored at http://archive.ubuntu.com/ubuntu/dists/impish/main/ The distribution code name is important. Now imagine if someone is using an old, unsupported version of Ubuntu like Ubuntu 20.10 codenamed Groovy Gorilla. The sources.list file will contain repository URL like \"deb http://archive.ubuntu.com/ubuntu groovy main\". And then it becomes problematic because if you visit http://archive.ubuntu.com/ubuntu/dists URL, you won\u2019t find groovy folder here. Since Ubuntu 20.10 is no longer maintained, its folder has been removed. As a result, Ubuntu will show an error like \u2018release file not found\u2019 or \u2018error 404 repository not found\u2019.","title":"Source lists"},{"location":"linux-notes/#sourceslist-file-and-sourceslistd-directory","text":"If you look at the /etc/apt directory, you\u2019ll notice a directory called sources.list.d. The idea is that the primary sources.list file is for the official Ubuntu repositories and for any external repositories and PPA, you add a .list file (with the repository details) in this sources.list.d directory. This makes managing the repositories easier as you don\u2019t mess up with the default repositories. The external repositories can be easily disabled (by adding # in front of the repository details) or removed (by removing its corresponding .list file).","title":"sources.list file and sources.list.d directory"},{"location":"markdown-notes/","text":"Markdown and mkdocs notes Project documentation with Markdown. MkDocs MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Visit https://www.mkdocs.org/ for complete reference on mkdocs. Building the site That's looking good. You're ready to deploy the first pass of your MkLorum documentation. First build the documentation: mkdocs build This will create a new directory, named site. Take a look inside the directory: $ ls site about fonts index.html license search.html css img js mkdocs sitemap.xml Notice that your source documentation has been output as two HTML files named index.html and about/index.html . You also have various other media that's been copied into the site directory as part of the documentation theme. You even have a sitemap.xml file and mkdocs/search_index.json . If you're using source code control such as git you probably don't want to check your documentation builds into the repository. Add a line containing site/ to your .gitignore file. echo \"site/\" >> .gitignore Deploying your pages User Pages sites are not tied to a specific project, and the site files are deployed to the main branch in a dedicated repository named with the GitHub account name. Therefore, you need working copies of two repositories on our local system. For example, consider the following file structure: my-project/ mkdocs.yml docs/ username.github.io/ After making and verifying updates to your project you need to change directories to the orgname.github.io repository and call the mkdocs gh-deploy command from there: cd ../username.github.io/ mkdocs gh-deploy --config-file ../mkdocs.yml --remote-branch main Password protected pages This plugin allows you to have password protected articles and pages in MKdocs. The content is encrypted with AES-256 in Python using PyCryptodome, and decrypted in the browser with Crypto-JS.","title":"Markdown"},{"location":"markdown-notes/#markdown-and-mkdocs-notes","text":"Project documentation with Markdown.","title":"Markdown and mkdocs notes"},{"location":"markdown-notes/#mkdocs","text":"MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Visit https://www.mkdocs.org/ for complete reference on mkdocs.","title":"MkDocs"},{"location":"markdown-notes/#building-the-site","text":"That's looking good. You're ready to deploy the first pass of your MkLorum documentation. First build the documentation: mkdocs build This will create a new directory, named site. Take a look inside the directory: $ ls site about fonts index.html license search.html css img js mkdocs sitemap.xml Notice that your source documentation has been output as two HTML files named index.html and about/index.html . You also have various other media that's been copied into the site directory as part of the documentation theme. You even have a sitemap.xml file and mkdocs/search_index.json . If you're using source code control such as git you probably don't want to check your documentation builds into the repository. Add a line containing site/ to your .gitignore file. echo \"site/\" >> .gitignore","title":"Building the site"},{"location":"markdown-notes/#deploying-your-pages","text":"User Pages sites are not tied to a specific project, and the site files are deployed to the main branch in a dedicated repository named with the GitHub account name. Therefore, you need working copies of two repositories on our local system. For example, consider the following file structure: my-project/ mkdocs.yml docs/ username.github.io/ After making and verifying updates to your project you need to change directories to the orgname.github.io repository and call the mkdocs gh-deploy command from there: cd ../username.github.io/ mkdocs gh-deploy --config-file ../mkdocs.yml --remote-branch main","title":"Deploying your pages"},{"location":"markdown-notes/#password-protected-pages","text":"This plugin allows you to have password protected articles and pages in MKdocs. The content is encrypted with AES-256 in Python using PyCryptodome, and decrypted in the browser with Crypto-JS.","title":"Password protected pages"},{"location":"python-notes/","text":"Python tips and tricks A small collection of notes about python tricks. How to intall python packages in an offline server Want to install python libs and their dependencies offline? Follow these steps on a machine with the same os, network connected, and python installed: Online machine Create a requirements.txt file with similar content (Note - these are the libraries you wish to download): Flask==0.12 requests>=2.7.0 scikit-learn==0.19.1 numpy==1.14.3 pandas==0.22.0 One option for creating the requirements file is to use pip freeze > requirements.txt . This will list all libraries in your environment. Then you can go in to requirements.txt and remove un-needed ones. Execute command mkdir wheelhouse && pip download -r requirements.txt -d wheelhouse to download libs and their dependencies to directory wheelhouse Copy requirements.txt into wheelhouse directory Archive wheelhouse into wheelhouse.tar.gz with tar -zcf wheelhouse.tar.gz wheelhouse Offline machine Upload wheelhouse.tar.gz to your target machine: Execute tar -zxf wheelhouse.tar.gz to extract the files Execute pip install -r wheelhouse/requirements.txt --no-index --find-links wheelhouse to install the libs and their dependencies","title":"Python"},{"location":"python-notes/#python-tips-and-tricks","text":"A small collection of notes about python tricks.","title":"Python tips and tricks"},{"location":"python-notes/#how-to-intall-python-packages-in-an-offline-server","text":"Want to install python libs and their dependencies offline? Follow these steps on a machine with the same os, network connected, and python installed:","title":"How to intall python packages in an offline server"},{"location":"python-notes/#online-machine","text":"Create a requirements.txt file with similar content (Note - these are the libraries you wish to download): Flask==0.12 requests>=2.7.0 scikit-learn==0.19.1 numpy==1.14.3 pandas==0.22.0 One option for creating the requirements file is to use pip freeze > requirements.txt . This will list all libraries in your environment. Then you can go in to requirements.txt and remove un-needed ones. Execute command mkdir wheelhouse && pip download -r requirements.txt -d wheelhouse to download libs and their dependencies to directory wheelhouse Copy requirements.txt into wheelhouse directory Archive wheelhouse into wheelhouse.tar.gz with tar -zcf wheelhouse.tar.gz wheelhouse","title":"Online machine"},{"location":"python-notes/#offline-machine","text":"Upload wheelhouse.tar.gz to your target machine: Execute tar -zxf wheelhouse.tar.gz to extract the files Execute pip install -r wheelhouse/requirements.txt --no-index --find-links wheelhouse to install the libs and their dependencies","title":"Offline machine"}]}